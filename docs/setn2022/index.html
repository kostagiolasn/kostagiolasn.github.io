<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Project Page Template</title>

  <link href="./assets/bootstrap.min.css" rel="stylesheet">
  <link href="./assets/font.css" rel="stylesheet" type="text/css">
  <link href="./assets/style.css" rel="stylesheet" type="text/css">
</head>
<!-- === Header Ends === -->


<body>


<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="title", style="padding-top: 25pt;">  <!-- Set padding as 10 if title is with two lines. -->
      Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models
    </div>
  </div>
  <!-- === Title Ends === -->
  <div class="author">
    <a href="mailto:n.kostagiolas@cyi.ac.cy" target="_blank">Nikos Kostagiolas</a><sup>1</sup>&nbsp;
    <span>Mihalis Nicolaou<sup>1</sup>,</span>
    <span>Yannis Panagakis<sup>2</sup>,</span>
  </div>
  <div class="institution">
    <span><sup>1</sup>The Cyprus Institute,</span>
    <span><sup>2</sup>National and Kapodistrian University of Athens</span>
  </div>
  <div class="link">
    <a href="#" target="_blank">[Paper]</a>&nbsp;
    <a href="https://github.com/kostagiolasn/Unsupervised-Discovery-of-Semantic-Concepts-in-Satellite-Imagery-with-Style-based-Wavelet-driven-Gen" target="_blank">[Code]</a>
  </div>
  <div class="teaser">
    <img src="figures/teaser.jpg">
  </div>
</div>
<!-- === Home Section Ends === -->


<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Abstract</div>
  <div class="body">
    In recent years, considerable advancements have been made in the area of Generative Adversarial Networks (GANs), particularly with the advent of style-based architectures that address many key shortcomings - both in terms of modeling capabilities and network interpretability. Despite these improvements, the adoption of such approaches in the domain of satellite imagery is not straightforward. Typical vision datasets used in generative tasks are well-aligned and annotated, and exhibit limited variability. In contrast, satellite imagery exhibits great spatial and spectral variability, wide presence of fine, high-frequency details, while the tedious nature of annotating satellite imagery leads to annotation scarcity - further motivating developments in unsupervised learning. In this light, we present the first pre-trained style- and wavelet-based GAN model that can readily synthesize a wide gamut of realistic satellite images in a variety of settings and conditions - while also preserving high-frequency information. Furthermore, we show that by analyzing the intermediate activations of our network, one can discover a multitude of interpretable semantic directions that facilitate the guided synthesis of satellite images in terms of high-level concepts (e.g., urbanization) without using any form of supervision. Via a set of qualitative and quantitative experiments we demonstrate the efficacy of our framework, in terms of suitability for downstream tasks (e.g., data augmentation), quality of synthetic imagery, as well as generalization capabilities to unseen datasets.
  </div>
</div>
<!-- === Overview Section Ends === -->


<!-- === Result Section Starts === -->
<div class="section">
  <div class="title">Results</div>
  <div class="body">
    Uncurated satellite imagery generations generated by our SWAGAN model, trained on the RESISC-45 dataset.

    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="figures/generations.png" width="90%"></td>
      </tr>
    </table>

    Example of edits moving along the first semantic direction (urbanization shift)
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp1/1.jpg" width="100%"></td>
        <td><img src="gif/comp1/2.png" width="100%"></td>
        <td><img src="gif/comp1/3.png" width="100%"></td>
        <td><img src="gif/comp1/7.png" width="100%"></td>
        <td><img src="gif/comp1/9.png" width="100%"></td>
        <td><img src="gif/comp1/10.png" width="100%"></td>
        <td><img src="gif/comp1/11.png" width="100%"></td>
        <td><img src="gif/comp1/13.png" width="100%"></td>
      </tr>
    </table>

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp1/1_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/2_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/3_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/7_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/9_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/10_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/11_proper.gif" width="100%"></td>
        <td><img src="gif/comp1/13_proper.gif" width="100%"></td>
      </tr>
    </table>

    Example of edits moving along the third semantic direction (vertical/horizontal axis structure reinforcement, depending on the edit direction).

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
         <td><img src="gif/comp3/1.png" width="100%"></td>
        <td><img src="gif/comp3/2.png" width="100%"></td>
        <td><img src="gif/comp3/3.png" width="100%"></td>
        <td><img src="gif/comp3/4.png" width="100%"></td>
        <td><img src="gif/comp3/5.png" width="100%"></td>
      </tr>
    </table>
    
    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp3/1_proper.gif" width="100%"></td>
        <td><img src="gif/comp3/2_proper.gif" width="100%"></td>
        <td><img src="gif/comp3/3_proper.gif" width="100%"></td>
        <td><img src="gif/comp3/4_proper.gif" width="100%"></td>
        <td><img src="gif/comp3/5_proper.gif" width="100%"></td>
      </tr>
    </table>

    Example of edits moving along the fourth semantic direction (main/secondary structure reinforcement, depending on the edit direction).

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
         <td><img src="gif/comp4/1.png" width="100%"></td>
        <td><img src="gif/comp4/2.png" width="100%"></td>
        <td><img src="gif/comp4/3.png" width="100%"></td>
        <td><img src="gif/comp4/4.png" width="100%"></td>
        <td><img src="gif/comp4/5.png" width="100%"></td>
      </tr>
    </table>

    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp4/1_proper.gif" width="100%"></td>
        <td><img src="gif/comp4/2_proper.gif" width="100%"></td>
        <td><img src="gif/comp4/3_proper.gif" width="100%"></td>
        <td><img src="gif/comp4/4_proper.gif" width="100%"></td>
        <td><img src="gif/comp4/5_proper.gif" width="100%"></td>
      </tr>
    </table>

    Example of edits moving along the fifth semantic direction (road structure addition/removal, depending on the edit direction).

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp5/1.png" width="100%"></td>
        <td><img src="gif/comp5/2.png" width="100%"></td>
        <td><img src="gif/comp5/3.png" width="100%"></td>
        <td><img src="gif/comp5/4.png" width="100%"></td>
        <td><img src="gif/comp5/5.png" width="100%"></td>
        <td><img src="gif/comp5/6.png" width="100%"></td>
      </tr>
    </table>

    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp5/1_proper.gif" width="100%"></td>
        <td><img src="gif/comp5/2_proper.gif" width="100%"></td>
        <td><img src="gif/comp5/3_proper.gif" width="100%"></td>
        <td><img src="gif/comp5/4_proper.gif" width="100%"></td>
        <td><img src="gif/comp5/5_proper.gif" width="100%"></td>
        <td><img src="gif/comp5/6_proper.gif" width="100%"></td>
      </tr>
    </table>

    Example of edits moving along the seventh semantic direction (flora growth/diminishment, depending on the edit direction).

    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp7/1.png" width="100%"></td>
        <td><img src="gif/comp7/2.png" width="100%"></td>
        <td><img src="gif/comp7/3.png" width="100%"></td>
        <td><img src="gif/comp7/4.png" width="100%"></td>
        <td><img src="gif/comp7/5.png" width="100%"></td>
        <td><img src="gif/comp7/6.png" width="100%"></td>
      </tr>
    </table>

    <!-- Adjust the number of rows and columns (EVERY project differs). -->
    <table width="100%" style="margin: 20pt 0; text-align: center;">
      <tr>
        <td><img src="gif/comp7/1_proper.gif" width="100%"></td>
        <td><img src="gif/comp7/2_proper.gif" width="100%"></td>
        <td><img src="gif/comp7/3_proper.gif" width="100%"></td>
        <td><img src="gif/comp7/4_proper.gif" width="100%"></td>
        <td><img src="gif/comp7/5_proper.gif" width="100%"></td>
        <td><img src="gif/comp7/6_proper.gif" width="100%"></td>
      </tr>
    </table>

    Demo video here.

    <!-- Adjust the frame size based on the demo (EVERY project differs). -->
    <div style="position: relative; padding-top: 50%; margin: 20pt 0; text-align: center;">
      <iframe src="https://via.placeholder.com/900x450" frameborder=0
              style="position: absolute; top: 2.5%; left: 2.5%; width: 95%; height: 100%;"
              allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
              allowfullscreen></iframe>
    </div>
  </div>
</div>
<!-- === Result Section Ends === -->


<!-- === Reference Section Starts === -->
<div class="section">
  <div class="bibtex">BibTeX</div>
<pre>
@article{2208.02089,
author = {Nikos Kostagiolas and Mihalis A. Nicolaou and Yannis Panagakis},
title = {Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models},
venue = {SETN},
year = {2022}
}
</pre>

  <!-- BZ: we should give other related work enough credits, -->
  <!--     so please include some most relevant work and leave some comment to summarize work and the difference. -->
  <div class="ref">Related Work</div>
  <div class="citation">
    <div class="image"><img src="figures/swagan.png"></div>
    <div class="comment">
      <a href="https://arxiv.org/abs/2102.06108" target="_blank">
        Gal et al.
        SWAGAN: A Style-based Wavelet-driven Generative Model.
        ACM Transactions on Graphics Volume 40, Issue 4, August 2021.</a><br>
      <b>Comment:</b>
      First paper to propose frequency-aware style-based image generation.
    </div>
  </div>
  <div class="citation">
    <div class="image"><img src="figures/sefa.png"></div>
    <div class="comment">
      <a href="https://arxiv.org/abs/2007.06600" target="_blank">
        Shen, Yujun and Zhou, Bolei.
        Closed-Form Factorization of Latent Semantics in GANs.
        CVPR, 2021.</a><br>
      <b>Comment:</b>
      First paper to propose and apply the closed-form factorization algorithm for the discovery of meaningful semantic directions on image data.
    </div>
  </div>
</div>
<!-- === Reference Section Ends === -->


</body>
</html>

